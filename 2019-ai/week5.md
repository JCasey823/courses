A. Read the following classic paper, which revolutionized machine translation in 1990, and answer the proceeding questions. http://www.ling.upenn.edu/courses/Spring_2011/cogs502/Brown1990.pdf

(a) Does this model accurately translate phrases longer than a single word? Explain.

(b) How is the Markov assumption being used in this paper?

(c) They suggest that a trigram model would improve the performance of their system. Why would this be?

(d)  What is the "generative story" of the translation model? That is, how does the model suppose that translations are generated, and how does this relate to the noisy channel model?

(e)  What are the prior and posterior in the first equation, and what do they signify?

(f)  What is the formula that describes the process of selecting the "best sentence" in section 1?

(g)  What are the parameters in the translation model, and how are they estimated?

(h)  What is a "distortion?"

(i)  What is an "alignment?"

B.

(a) Graphically, what effect does the bias term have on the logistic function in logistic regression?

(b) Describe the difference(s) between stochastic gradient descent and gradient descent.

(c) Given a convex problem surface, what do we use to find the direction of steepest ascent?

(d) Which beta terms can be skipped during the update stage of logistic regression with SGD?

(e) What are the elements of the gradient vector?  What do they represent in terms of optimization?
